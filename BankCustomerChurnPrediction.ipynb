{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dbb05b2a",
   "metadata": {},
   "source": [
    "# Bank Customer Churn Prediction Analysis\n",
    "**Problem definition-** A fictitious bank, serving over 10,000 customers across 3 European countries, is facing a crucial challenge with the customer leaving their business, which has gradually increased over time. The bank objects to address this issue proactively by developing and deploying a predictive model that can identify at-risk customers before they decide to leave. This leads to the enhancement of techniques and strategies for customer retention with low-cost efficiency.\n",
    "\n",
    "**Project Goal-** The primary objective of this project is to deploy a robust and generalized churn prediction model that helps banks forecast customer churn from both existing and new, unseen data. This will allow the bank to take pointed actions to reduce churn ratios. In addition, the project also aims to understand and disclose the underlying patterns and statistics about factors influencing customer churn. Specifically, will explore relationships between churn and demographic factors for instance age, income, and region. Behavioral factors like the count of products registered by customers, and number of years being as a customer in the bank. \n",
    "To achieve these objectives, I will employ a combination of three machine learning algorithms to predict the target variable. Those are a linear model, a non-linear model, and Ensemble methods to optimize the prediction rate. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68e848d6",
   "metadata": {},
   "source": [
    "## Data Understanding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41934ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic libraries for EDA\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "from seaborn import heatmap\n",
    "\n",
    "# Upsampling library\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# modelling\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# validation and evaluation metrics libraries\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.metrics import roc_auc_score, roc_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7136a79c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loads dataset\n",
    "dfm = pd.read_csv(r\"C:\\Users\\naniv\\Downloads\\UOP\\Semester_3\\Customer_Analytics\\Capstone_project\\BankData.csv\")\n",
    "dfm.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fce26689",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataframe shape\n",
    "print(f'There are {dfm.shape[0]} rows and {dfm.shape[1]} columns in the dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "505aac01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data types of the attributes\n",
    "dfm.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b97d045",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataframe information\n",
    "dfm.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f8bdf45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checks duplicates\n",
    "dupl = dfm[dfm['CustomerId'].duplicated()]\n",
    "dupl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc6563e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checks missing values\n",
    "\n",
    "dfm.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f96f4016",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set id column as index\n",
    "#dfm = dfm.set_index('id')\n",
    "dfm = dfm.set_index('RowNumber')\n",
    "dfm.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d60b9ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# uniqueness of data available \n",
    "\n",
    "a = dfm['CustomerId'].nunique()\n",
    "b = dfm.shape[0]\n",
    "\n",
    "if a == b:\n",
    "    print('Each row in the dataframe represents individual customers. Proceed further :)')\n",
    "else:\n",
    "    print(' There are duplicate customers in the datase. Please Check!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5193be91",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# statistical summary of the dataframe\n",
    "\n",
    "dfm.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e9f871b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfm.describe(include = 'object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "408d8508",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data distributions of the numerical variables\n",
    "\n",
    "fig,ax = plt.subplots(3,2, figsize = (14,14))\n",
    "\n",
    "ax[0,0].hist(dfm['CreditScore'])\n",
    "ax[0,0].set_title('CreditScore')\n",
    "ax[0,1].hist(dfm['Age'])\n",
    "ax[0,1].set_title('Age')\n",
    "ax[1,0].hist(dfm['Tenure'])\n",
    "ax[1,0].set_title('Tenure')\n",
    "ax[1,1].hist(dfm['EstimatedSalary'])\n",
    "ax[1,1].set_title('EstimatedSalary')\n",
    "ax[1,1].set_ylim(950,None)\n",
    "ax[2,0].hist(dfm['NumOfProducts'])\n",
    "ax[2,0].set_title('Number of products')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23258694",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Ther is class imbalance in target variable \n",
    "# class imbalance is common because most of the customer do not leave the service only very few leave bank \n",
    "# ratio of target variable is 4:1\n",
    "#dfm['Exited'].value_counts()[0]\n",
    "#dfm['Exited'].value_counts()[1]\n",
    "dfm['Exited'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9df8146b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# percentage of data belonging to minority class\n",
    "class1per = (dfm['Exited'].value_counts()[1] / dfm.shape[0]) * 100\n",
    "print(f'Percentage of Minority class {class1per:.2f} %')\n",
    "# imbalance is moderate and need to be addressed using data mitigation techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b310fb40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target variable distribution\n",
    "sns.displot(dfm['Exited'])\n",
    "plt.title('Target Variable Distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47fe6511",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# categorical variables distribution\n",
    "\n",
    "catcols09 = ['Gender', 'Geography','HasCrCard', 'IsActiveMember']\n",
    "\n",
    "for i in catcols09:\n",
    "    sns.histplot(dfm[i])\n",
    "    plt.title(f'Distribution of {i}')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba4e1b39",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Data validations\n",
    "\n",
    "catcols09 = ['Gender', 'Geography','HasCrCard', 'IsActiveMember']\n",
    "\n",
    "for t in catcols09:\n",
    "    count = dfm[t].value_counts()\n",
    "    \n",
    "    unq_valper = count / len(dfm) * 100 \n",
    "    print(f'Percentage of unique values of column {t}')\n",
    "    print(unq_valper)\n",
    "    print('-----------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cd9d762",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Validations\n",
    "numcols09 = ['CreditScore', 'Age','Tenure', 'NumOfProducts','Balance','EstimatedSalary' ]\n",
    "\n",
    "for m in numcols09:\n",
    "    count = dfm[m].value_counts()\n",
    "    \n",
    "    unq_valper = (count / len(dfm) * 100 ).nlargest(3)\n",
    "    print(f'Percentage of unique values of column {m}')\n",
    "    print(unq_valper)\n",
    "    print('-----------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1510f0f4",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c0e8f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pair plot for correlation\n",
    "\n",
    "sns.pairplot(dfm)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b76f574a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlation between features\n",
    "# using spearman Method\n",
    "corr11 = dfm.corr()\n",
    "corr11\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2324f578",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visual representation of correlation\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (8,8))\n",
    "ax = heatmap(\n",
    "corr11,\n",
    "annot = True,\n",
    "ax = ax,\n",
    "cmap = \"RdBu_r\",\n",
    "vmin = 1,\n",
    "vmax = 1,\n",
    ")\n",
    "fontdict = { 'fontsize': 20}\n",
    "ax.set_title(\"Heatmap of Correlation between continuous variables\", fontdict= fontdict, pad =40)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d19def",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#age has highest correlation with target variable\n",
    "# lets look in to patterns of age vs cat variable by exited or not\n",
    "\n",
    "\n",
    "for i in catcols09:\n",
    "    sns.boxplot(data = dfm, x = dfm[i], y = 'Age', hue = 'Exited')\n",
    "    plt.title(f'{i} vs Age boxplot' )\n",
    "    plt.show()\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb9e693b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# skewness values to check data is skewed or not\n",
    "print(dfm.skew(numeric_only = True)) #threshold -1 to 1 \n",
    "# Age column is right skewed because life expectancy of european regions france, spain and germany is less than 84 since older are less represented and younger customers are more in dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f3647c0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Count plot comparing balance wtih cat cols by Exited\n",
    "borders = ['top','right']\n",
    "for i in catcols09:\n",
    "    ax = sns.barplot(data = dfm, x = dfm[i], y = 'Balance', hue = 'Exited',errwidth = 0)\n",
    "    for j in borders:\n",
    "        ax.spines[j].set_visible(False) # removes borders \n",
    "    ax.grid(True,which= 'major', axis = 'y', linestyle= '-',linewidth = 0.3,zorder = 0) # set gridlines\n",
    "    ax.set_axisbelow(True) # overlay bars from the gridlines\n",
    "    ax.set_title(f'Relation of {i} with Balance Amount')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c6c01a6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Validating findings in visualizations with acutal numbers \n",
    "#customer exited or not of average balance\n",
    "amnt0 = np.mean(dfm[dfm['Exited']==0]['Balance'])\n",
    "amnt1 = np.mean(dfm[dfm['Exited']== 1]['Balance'])\n",
    "print(f'Customer exited from Bank having average balance of {np.round(amnt0)} \\ncustomers stayed loyal with bank having average balance of {np.round(amnt1 )}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b30434",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Checks count of customers exited and not exited using number of products\n",
    "\n",
    "prod0=dfm[dfm['Exited'] == 0] ['NumOfProducts']\n",
    "prod1 = dfm[dfm['Exited']== 1] ['NumOfProducts']\n",
    "\n",
    "print('Customers using Number of products Not exited')\n",
    "print('--' * 20)\n",
    "print(prod0.value_counts())\n",
    "\n",
    "print('--' * 30)\n",
    "\n",
    "print('Customers using Number of products Exited')\n",
    "print('--' * 20)\n",
    "print(prod1.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2782055e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# visualize to support above results\n",
    "#negatively correlated num of products vs balance in bank account\n",
    "sns.scatterplot(data = dfm, x ='NumOfProducts',y= 'Balance', hue ='Exited')\n",
    "plt.title('Num Of Products Registered vs Balance Amount')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea71564",
   "metadata": {},
   "outputs": [],
   "source": [
    "# customers exited with less than average balance\n",
    " \n",
    "countbal = (dfm['Balance'] <= np.mean(dfm['Balance'])) & (dfm['Exited'] == 1 )\n",
    "countbal.value_counts()\n",
    "\n",
    "print(f'Number of Customers having less than average balance Exited the bank are {countbal.value_counts()[1]}' )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f0e49b0",
   "metadata": {},
   "source": [
    "## Data Preparation & Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe6e975e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# there are no duplicates and no missing values\n",
    "# Data cleaning\n",
    "cleaned_dfm = dfm.drop(labels = ['CustomerId', 'Surname'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f018c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoding categorical features\n",
    "df_encoded= pd.get_dummies(cleaned_dfm, drop_first = True)\n",
    "df_encoded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e8ab4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = df_encoded.drop(labels = ['Exited'], axis = 1) \n",
    "y1 = df_encoded['Exited']\n",
    "\n",
    "X_train1, X_test1, y_train1, y_test1 = train_test_split(X1,y1, test_size = 0.30, random_state = 42, stratify = y1)\n",
    "# stratify balance the imbalance data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97043c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaling data\n",
    "scaler = StandardScaler(with_mean = True)\n",
    "\n",
    "X_train1 = scaler.fit_transform(X_train1)\n",
    "X_test1 = scaler.transform(X_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61458344",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline model performance \n",
    "\n",
    "\n",
    "algorithms = {\"logistic Regression\": LogisticRegression(),\n",
    "       \"Decision Tree\": DecisionTreeClassifier(),\n",
    "       \"Random Forest Classifier\": RandomForestClassifier()} # dictinory of supervised models\n",
    "\n",
    "\n",
    "for key , algo in algorithms.items():\n",
    "    \n",
    "    #fits the data in to the model\n",
    "    algo.fit(X_train1, y_train1)\n",
    "    \n",
    "    #Prediction\n",
    "    prediction = algo.predict(X_test1)\n",
    "    \n",
    "    #accuracy \n",
    "    acc = accuracy_score(y_test1, prediction)\n",
    "    print(f'Accuracy of {key} {acc:.2f} ')\n",
    "    \n",
    "    #Classification Report \n",
    "    report = classification_report(y_test1, prediction,zero_division=0)\n",
    "    print(f'Classification Report of  {key}')\n",
    "    print(report)\n",
    "    \n",
    "    \n",
    "    #confusion matrix \n",
    "    conf_mtrx = confusion_matrix(y_test1, prediction)\n",
    "    print(f\"Confusion Matrix {key}:\")\n",
    "    print(conf_mtrx)\n",
    "    print('--------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f588173",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dfc4b81",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# k fold  cross validation\n",
    "# used for model who have class imbalance in dataset\n",
    "\n",
    "kf = KFold(n_splits = 5)\n",
    "kf.get_n_splits(X1)\n",
    "\n",
    "print(kf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4646f8db",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, algo in algorithms.items():\n",
    "    kfoldscores = cross_val_score(algo, X_train1,y_train1 , cv = kf)\n",
    "    print(f'kfold Cross validation of {key} {kfoldscores}')\n",
    "    print('*************************')\n",
    "    print(f'Kfold cross validation score mean {kfoldscores.mean()}')\n",
    "    print('--------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da13c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upsampling distributions using SMOTE\n",
    "\n",
    "sm = SMOTE(sampling_strategy='auto', k_neighbors= 5)\n",
    "\n",
    "x_resamp , y_resamp = sm.fit_resample(X1,y1)\n",
    "\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(x_resamp,y_resamp, test_size = 0.30, random_state = 42, stratify = y_resamp)\n",
    "\n",
    "\n",
    "X_train2 = scaler.fit_transform(X_train2)\n",
    "X_test2 = scaler.transform(X_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3f475ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checks classes counts after upsampling and compares it with count of before upsampling\n",
    "y_resamp.value_counts(), y1.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74f605cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model performance after upsampling target variable\n",
    "\n",
    "algorithms = {\"logistic Regression\": LogisticRegression(),\n",
    "       \"Decision Tree\": DecisionTreeClassifier(),\n",
    "       \"Random Forest Classifier\": RandomForestClassifier()}\n",
    "\n",
    "\n",
    "for key , algo in algorithms.items():\n",
    "    \n",
    "    #fits the data in to the model\n",
    "    algo.fit(X_train2, y_train2)\n",
    "    \n",
    "    #Prediction\n",
    "    prediction = algo.predict(X_test2)\n",
    "    \n",
    "    #accuracy \n",
    "    acc = accuracy_score(y_test2, prediction)\n",
    "    print(f'Accuracy of {key} {acc:.2f} ')\n",
    "    \n",
    "    #Classification Report \n",
    "    report = classification_report(y_test2, prediction,zero_division=0)\n",
    "    print(f'Classification Report of  {key}')\n",
    "    print(report)\n",
    "    \n",
    "    \n",
    "    #confusion matrix \n",
    "    conf_mtrx = confusion_matrix(y_test2, prediction)\n",
    "    print(f\"Confusion Matrix {key}:\")\n",
    "    print(conf_mtrx)\n",
    "    print('--------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "832ad681",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# best model evaluation metrics and confusion matrix\n",
    "\n",
    "randforest = RandomForestClassifier()\n",
    "\n",
    "randforest.fit(X_train2, y_train2)\n",
    "\n",
    "prediction= randforest.predict(X_test2)\n",
    "\n",
    "acc = accuracy_score(y_test2, prediction)\n",
    "print(f'Accuracy {acc:.2f} ')\n",
    "\n",
    "clf_report =  classification_report(y_test2, prediction)\n",
    "print(f'Classification Report')\n",
    "print(clf_report)\n",
    "\n",
    "confu_matrix = confusion_matrix(y_test2, prediction)\n",
    "print('Confusion Matrix')\n",
    "print(confu_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dabf9590",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, algo in algorithms.items():\n",
    "    kfoldscores = cross_val_score(algo, X_train2,y_train2 , cv = 5)\n",
    "    print(f'kfold Cross validation of {key} {kfoldscores}')\n",
    "    print('*************************')\n",
    "    print(f'Kfold cross validation score mean {kfoldscores.mean()}')\n",
    "    print('--------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b890aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize confusion matrix\n",
    "\n",
    "cm_display = ConfusionMatrixDisplay(confusion_matrix = confu_matrix, display_labels = randforest.classes_)\n",
    "\n",
    "cm_display.plot()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb3ebf8c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Based on the f1 score and cross validation score considered random forest classifier as final model\n",
    "# Feature importances for the final model\n",
    "\n",
    "randforest = RandomForestClassifier()\n",
    "\n",
    "randforest.fit(X_train2, y_train2)\n",
    "\n",
    "print('Feature importances for Model Random Forest Classifier')\n",
    "print('------------------------------------------------------')\n",
    "for col , val in sorted(\n",
    "    zip(X1.columns, \n",
    "       randforest.feature_importances_,\n",
    "       ),\n",
    "    key = lambda x: x[1],\n",
    "    reverse = True,\n",
    "    ):\n",
    "    print(f'{col:15}{val:10.3f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "078a28a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# roc auc score\n",
    "rocauc = roc_auc_score(y_test2, prediction)\n",
    "rocauc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd0f8206",
   "metadata": {},
   "source": [
    "**References**\n",
    "\n",
    "\n",
    "https://www.kaggle.com/datasets/saurabhbadole/bank-customer-churn-prediction-dataset\n",
    "https://creativecommons.org/licenses/by-nc-sa/4.0/\n",
    "https://matplotlib.org/stable/api/_as_gen/matplotlib.axes.Axes.grid.html\n",
    "https://en.wikipedia.org/wiki/List_of_European_countries_by_life_expectancya\n",
    "https://machinelearningmastery.com/tactics-to-combat-imbalanced-classes-in-your-machine-learning-dataset/\n",
    "https://scikit-learn.org/stable/auto_examples/compose/plot_column_transformer_mixed_types.html\n",
    "https://medium.com/@rithpansanga/choosing-the-right-size-a-look-at-the-differences-between-upsampling-and-downsampling-methods-daae83915c19#:~:text=If%20the%20focus%20is%20on,may%20be%20a%20better%20option.\n",
    "https://youtu.be/4SivdTLIwHc?feature=shared\n",
    "https://machinelearningmastery.com/smote-oversampling-for-imbalanced-classification/\n",
    "https://www.geeksforgeeks.org/spearmans-rank-correlation/\n",
    "https://aws.amazon.com/what-is/data-preparation/\n",
    "https://pandas.pydata.org/docs/reference/api/pandas.get_dummies.html\n",
    "https://scikit-learn.org/dev/modules/generated/sklearn.preprocessing.StandardScaler.html\n",
    "https://www.datacamp.com/tutorial/understanding-logistic-regression-python\n",
    "https://www.ibm.com/topics/decision-trees\n",
    "https://www.ibm.com/topics/random-forest"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
